

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Transformer Transducer Model &mdash; Openspeech v0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Transformer with CTC Model" href="Transformer with CTC.html" />
    <link rel="prev" title="Transformer Model" href="Transformer.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Openspeech
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">GETTING STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/intro.html">Why should I use openspeech?</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/intro.html#why-shouldn-t-i-use-openspeech">Why shouldn’t I use openspeech?</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/intro.html#model-architectures">Model architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/intro.html#get-started">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/intro.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/intro.html#troubleshoots-and-contributing">Troubleshoots and Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/intro.html#citation">Citation</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/hydra_configs.html">Openspeech’s Hydra configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/configs.html">Openspeech’s configurations</a></li>
</ul>
<p class="caption"><span class="caption-text">MODEL ARCHITECTURES</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Openspeech Model.html">Openspeech Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Conformer.html">Conformer Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Conformer LSTM.html">Conformer LSTM Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Conformer Transducer.html">Conformer Transducer Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Deep CNN with Joint CTC LAS.html">Deep CNN with Joint CTC LAS Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="DeepSpeech2.html">DeepSpeech2 Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Jasper5x3.html">Jasper5x3 Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Jasper10x5.html">Jasper10x5 Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Joint CTC Conformer LSTM.html">Joint CTC Conformer LSTM Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Joint CTC LAS.html">Joint CTC LAS Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Joint CTC Transformer.html">Joint CTC Transformer Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Listen Attend Spell.html">Listen Attend Spell Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Listen Attend Spell (location-aware).html">Listen Attend Spell (location-aware) Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Listen Attend Spell (multi-head).html">Listen Attend Spell (multi-head) Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="QuartzNet5x5.html">QuartzNet 5x5 Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="QuartzNet10x5.html">QuartzNet 10x5 Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="QuartzNet15x5.html">QuartzNet 15x5 Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="RNN Transducer.html">RNN Transducer Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Transformer.html">Transformer Model</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Transformer Transducer Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">Transformer Transducer Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-openspeech.models.transformer_transducer.configurations">Transformer Transducer Model Configuration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Transformer with CTC.html">Transformer with CTC Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="VGG Transformer.html">VGG Transformer Model</a></li>
</ul>
<p class="caption"><span class="caption-text">LIBRARY REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Audio.html">Audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="Criterion.html">Criterion</a></li>
<li class="toctree-l1"><a class="reference internal" href="Data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="Decoders.html">Decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="Encoders.html">Encoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="Modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="Optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="Beam Search.html">Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="Vocabulary.html">Vocabulary</a></li>
<li class="toctree-l1"><a class="reference internal" href="Metric.html">Metric</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Openspeech</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Transformer Transducer Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/Transformer Transducer.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="transformer-transducer-model">
<h1>Transformer Transducer Model<a class="headerlink" href="#transformer-transducer-model" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>Transformer Transducer Model<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-openspeech.models.transformer_transducer.model"></span><dl class="py class">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel">
<em class="property">class </em><code class="sig-prename descclassname">openspeech.models.transformer_transducer.model.</code><code class="sig-name descname">TransformerTransducerModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">configs</span><span class="p">:</span> <span class="n">omegaconf.dictconfig.DictConfig</span></em>, <em class="sig-param"><span class="n">vocab</span><span class="p">:</span> <span class="n"><a class="reference internal" href="Vocabulary.html#openspeech.vocabs.vocab.Vocabulary" title="openspeech.vocabs.vocab.Vocabulary">openspeech.vocabs.vocab.Vocabulary</a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Transformer-Transducer is that every layer is identical for both audio and label encoders.
Unlike the basic transformer structure, the audio encoder and label encoder are separate.
So, the alignment is handled by a separate forward-backward process within the RNN-T architecture.
And we replace the LSTM encoders in RNN-T architecture with Transformer encoders.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configs</strong> (<em>DictConfig</em>) – configuraion set</p></li>
<li><p><strong>vocab</strong> (<a class="reference internal" href="Vocabulary.html#openspeech.vocabs.vocab.Vocabulary" title="openspeech.vocabs.vocab.Vocabulary"><em>Vocabulary</em></a>) – vocab of training data</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs:</dt><dd><dl class="simple">
<dt>inputs (torch.FloatTensor): A input sequence passed to encoders. Typically for inputs this will be a padded</dt><dd><p><cite>FloatTensor</cite> of size <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">seq_length,</span> <span class="pre">dimension)</span></code>.</p>
</dd>
</dl>
<p>input_lengths (torch.LongTensor): The length of input tensor. <code class="docutils literal notranslate"><span class="pre">(batch)</span></code></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Result of model predictions.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>y_hats (torch.FloatTensor)</p></li>
</ul>
</p>
</dd>
</dl>
<dl class="py method">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel.decode">
<code class="sig-name descname">decode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">encoder_outputs</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git216f813 ))">torch.Tensor</a></span></em>, <em class="sig-param"><span class="n">max_length</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git216f813 ))">torch.Tensor</a><a class="reference internal" href="_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel.decode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Decode <cite>encoder_outputs</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_outputs</strong> (<em>torch.FloatTensor</em>) – A output sequence of encoders. <cite>FloatTensor</cite> of size
<code class="docutils literal notranslate"><span class="pre">(seq_length,</span> <span class="pre">dimension)</span></code></p></li>
<li><p><strong>max_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – max decoding time step</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>model’s predictions.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>y_hats (torch.IntTensor)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git216f813 ))">torch.Tensor</a></span></em>, <em class="sig-param"><span class="n">input_lengths</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git216f813 ))">torch.Tensor</a></span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)">str</a><span class="p">, </span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git216f813 ))">torch.Tensor</a><span class="p">]</span><a class="reference internal" href="_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Decode <cite>encoder_outputs</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>torch.FloatTensor</em>) – A input sequence passed to encoders. Typically for inputs this will be a padded
<cite>FloatTensor</cite> of size <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">seq_length,</span> <span class="pre">dimension)</span></code>.</p></li>
<li><p><strong>input_lengths</strong> (<em>torch.LongTensor</em>) – The length of input tensor. <code class="docutils literal notranslate"><span class="pre">(batch)</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Result of model predictions.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>outputs (dict)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel.test_step">
<code class="sig-name descname">test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batch</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></span></em>, <em class="sig-param"><span class="n">batch_idx</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" title="(in Python v3.9)">collections.OrderedDict</a><a class="reference internal" href="_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel.test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagate a <cite>inputs</cite> and <cite>targets</cite> pair for test.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><p>batch (tuple): A train batch contains <cite>inputs</cite>, <cite>targets</cite>, <cite>input_lengths</cite>, <cite>target_lengths</cite>
batch_idx (int): The index of batch</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>loss for training</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>loss (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git216f813 ))">torch.Tensor</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel.training_step">
<code class="sig-name descname">training_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batch</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></span></em>, <em class="sig-param"><span class="n">batch_idx</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" title="(in Python v3.9)">collections.OrderedDict</a><a class="reference internal" href="_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel.training_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagate a <cite>inputs</cite> and <cite>targets</cite> pair for training.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><p>batch (tuple): A train batch contains <cite>inputs</cite>, <cite>targets</cite>, <cite>input_lengths</cite>, <cite>target_lengths</cite>
batch_idx (int): The index of batch</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>loss for training</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>loss (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git216f813 ))">torch.Tensor</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel.validation_step">
<code class="sig-name descname">validation_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batch</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></span></em>, <em class="sig-param"><span class="n">batch_idx</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" title="(in Python v3.9)">collections.OrderedDict</a><a class="reference internal" href="_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel.validation_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagate a <cite>inputs</cite> and <cite>targets</cite> pair for validation.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><p>batch (tuple): A train batch contains <cite>inputs</cite>, <cite>targets</cite>, <cite>input_lengths</cite>, <cite>target_lengths</cite>
batch_idx (int): The index of batch</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>loss for training</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>loss (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git216f813 ))">torch.Tensor</a>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-openspeech.models.transformer_transducer.configurations">
<span id="transformer-transducer-model-configuration"></span><h2>Transformer Transducer Model Configuration<a class="headerlink" href="#module-openspeech.models.transformer_transducer.configurations" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="openspeech.models.transformer_transducer.configurations.TransformerTransducerConfigs">
<em class="property">class </em><code class="sig-prename descclassname">openspeech.models.transformer_transducer.configurations.</code><code class="sig-name descname">TransformerTransducerConfigs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)">str</a></span> <span class="o">=</span> <span class="default_value">'transformer_transducer'</span></em>, <em class="sig-param"><span class="n">encoder_dim</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">512</span></em>, <em class="sig-param"><span class="n">d_ff</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">2048</span></em>, <em class="sig-param"><span class="n">num_audio_layers</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">18</span></em>, <em class="sig-param"><span class="n">num_label_layers</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">2</span></em>, <em class="sig-param"><span class="n">num_attention_heads</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">8</span></em>, <em class="sig-param"><span class="n">audio_dropout_p</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)">float</a></span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">label_dropout_p</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)">float</a></span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">decoder_hidden_state_dim</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">512</span></em>, <em class="sig-param"><span class="n">decoder_output_dim</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">512</span></em>, <em class="sig-param"><span class="n">conv_kernel_size</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">31</span></em>, <em class="sig-param"><span class="n">max_positional_length</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">5000</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)">str</a></span> <span class="o">=</span> <span class="default_value">'adam'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/openspeech/models/transformer_transducer/configurations.html#TransformerTransducerConfigs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.configurations.TransformerTransducerConfigs" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the configuration class to store the configuration of
a <code class="xref py py-class docutils literal notranslate"><span class="pre">TransformerTransducer</span></code>.</p>
<p>It is used to initiated an <cite>TransformerTransducer</cite> model.</p>
<p>Configuration objects inherit from :class: <cite>~openspeech.dataclass.configs.OpenspeechDataclass</cite>.</p>
<dl class="simple">
<dt>Configurations:</dt><dd><p>model_name (str): Model name (default: transformer_transducer)
extractor (str): The CNN feature extractor. (default: conv2d_subsample)
d_model (int): Dimension of model. (default: 512)
d_ff (int): Dimension of feed forward network. (default: 2048)
num_attention_heads (int): The number of attention heads. (default: 8)
num_audio_layers (int): The number of audio layers. (default: 18)
num_label_layers (int): The number of label layers. (default: 2)
audio_dropout_p (float): The dropout probability of encoder. (default: 0.1)
label_dropout_p (float): The dropout probability of decoder. (default: 0.1)
decoder_hidden_state_dim (int): Hidden state dimension of decoder (default: 512)
decoder_output_dim (int): dimension of model output. (default: 512)
conv_kernel_size (int): Kernel size of convolution layer. (default: 31)
max_positional_length (int): Max length of positional encoding. (default: 5000)
optimizer (str): Optimizer for training. (default: adam)</p>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="Transformer with CTC.html" class="btn btn-neutral float-right" title="Transformer with CTC Model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="Transformer.html" class="btn btn-neutral float-left" title="Transformer Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Kim, Soohwan and Ha, Sangchun and Cho, Soyoung.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>